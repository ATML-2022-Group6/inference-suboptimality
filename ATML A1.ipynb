{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b22c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "from flax import linen as nn\n",
    "from flax import optim\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import math\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2f288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal(x, mean=None, logvar=None,repeat=False):\n",
    "    if mean is None:\n",
    "        mean = jnp.zeros(jnp.shape(x), dtype = x.dtype)\n",
    "    if logvar is None:\n",
    "        logvar = jnp.zeros(jnp.shape(x), dtype = x.dtype)\n",
    "    if repeat:\n",
    "        D = jnp.shape(x)[2]\n",
    "        term1 = D * jnp.log(jnp.array([2.*math.pi]))\n",
    "        return -.5 * (term1 + logvar.sum(1) + ((x - mean).pow(2)/jnp.exp(logvar)).sum(2))\n",
    "\n",
    "    return -0.5 * (logvar.sum(1) + ((x - mean).pow(2) / jnp.exp(logvar)).sum(1))\n",
    "\n",
    "def log_bernoulli(logit, target, repeat = False):\n",
    "    if repeat:\n",
    "        return -(jnp.clip(logit, min=0) - logit * target\n",
    "             + jnp.log(1. + jnp.exp(-jnp.abs(logit)))).sum(2) #sum over dimensions\n",
    "    \n",
    "    loss = -nn.relu(logit) + jnp.multiply(target, logit) - jnp.log(1. + jnp.exp(-jnp.abs(logit)))\n",
    "    while len(loss.size()) > 1:\n",
    "        loss = loss.sum(-1)\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f256f50f",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdd3cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def setup(self, act_func, h_s, z_size):\n",
    "        self.fc1 = nn.Dense(h_s)\n",
    "        self.fc2 = nn.Dense(h_s)\n",
    "        self.fc3 = nn.Dense(z_size*2)\n",
    "        self.x_info_layer = nn.Dense(z_size)\n",
    "        self.act_func = act_func\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.act_func(self.fc1(x))\n",
    "        x = self.act_func(self.fc2(x))\n",
    "        x_info = self.act_func(self.x_info_layer(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        mean, logvar = x[:, :self.z_size], x[:, self.z_size:]\n",
    "        return mean, logvar, x_info\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def setup(self, act_func):\n",
    "        self.fc4 = nn.Dense(200)\n",
    "        self.fc5 = nn.Dense(200)\n",
    "        self.fc6 = nn.Dense(784)\n",
    "        self.act_func = act_func\n",
    "    \n",
    "    def __call__(self, z, act_func):\n",
    "        z = act_func(self.fc4(z))\n",
    "        z = act_func(self.fc5(z))\n",
    "        z = self.fc6(z)\n",
    "        return z\n",
    "    \n",
    "class VAE(nn.Module):\n",
    "    def setup(self, hps):\n",
    "        self.has_flow = hps.has_flow\n",
    "#         self.use_cuda = hps.cuda\n",
    "        self.hamiltonian_flow = hps.hamiltonian_flow\n",
    "\n",
    "        self.encode = Encoder(hps.act_func, hps.h_s, hps.z_size)\n",
    "        self.decode = Decoder(hps.act_func)\n",
    "        \n",
    "        if hps.has_flow:\n",
    "            self.q_dist = Flow(self, n_flows=hps.n_flows)\n",
    "#             if self.use_cuda:\n",
    "#                 self.q_dist.cuda()\n",
    "\n",
    "    def __call__(self, x, k=1, warmup_const=1.):\n",
    "        x = x.repeat(k, 1)\n",
    "        mean, logvar, x_info = self.encode(x)\n",
    "        \n",
    "        if self.hamiltonian_flow:\n",
    "            z, logpz, logqz = self.sample(mean, logvar, grad_fn=grad_U, x_info=x_info)\n",
    "        else:\n",
    "            z, logpz, logqz = self.sample(mean, logvar, x_info=x_info)\n",
    "\n",
    "        logit = self.decode(z)\n",
    "        logpx = log_bernoulli(logit, x)\n",
    "        elbo = logpx + logpz - warmup_const * logqz \n",
    "\n",
    "        # need correction for Tensor.repeat\n",
    "        elbo = log_mean_exp(elbo.view(k, -1).transpose(0, 1))\n",
    "        elbo = jnp.mean(elbo)\n",
    "\n",
    "        logpx = jnp.mean(logpx)\n",
    "        logpz = jnp.mean(logpz)\n",
    "        logqz = jnp.mean(logqz)\n",
    "\n",
    "        return elbo, logpx, logpz, logqz\n",
    "    \n",
    "    def U(z):\n",
    "        logpx = log_bernoulli(self.decode(z), x)\n",
    "        logpz = log_normal(z)\n",
    "        return -logpx - logpz  # energy as -log p(x, z)\n",
    "\n",
    "    # If hamiltonian flow\n",
    "    \n",
    "    #FIXX\n",
    "    def grad_U(z):\n",
    "        grad_outputs = jnp.ones(z.size(0))\n",
    "        grad = torchgrad(U(z), z, grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "        norm = torch.sqrt(torch.norm(grad, p=2, dim=1))\n",
    "        grad = grad / norm.view(-1, 1)\n",
    "        # grad = torch.clamp(grad, -10000, 10000)\n",
    "        return grad.detach()\n",
    "    \n",
    "    def sample(self, mean, logvar, grad_fn=lambda x: 1, x_info=None):\n",
    "        eps = random.normal(rng, mu.shape)\n",
    "        z = jnp.exp(0.5 * logvar)*eps + mean\n",
    "        logqz = log_normal(z, mean, logvar)\n",
    "        \n",
    "        if self.has_flow:\n",
    "            z, logprob = self.q_dist.forward(z, grad_fn, x_info)\n",
    "            logqz += logprob\n",
    "\n",
    "        zeros = jnp.zeros(z.size())\n",
    "        logpz = log_normal(z, zeros, zeros)\n",
    "\n",
    "        return z, logpz, logqz\n",
    "\n",
    "    def model():\n",
    "        return VAE()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e689397a",
   "metadata": {},
   "source": [
    "# HParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cba3afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams(object):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self._items = {}\n",
    "        for k, v in kwargs.items():\n",
    "            self._set(k, v)\n",
    "\n",
    "    def _set(self, k, v):\n",
    "        self._items[k] = v\n",
    "        setattr(self, k, v)\n",
    "\n",
    "    def parse(self, str_value):\n",
    "        hps = HParams(**self._items)\n",
    "        for entry in str_value.strip().split(\",\"):\n",
    "            entry = entry.strip()\n",
    "            if not entry:\n",
    "                continue\n",
    "            key, sep, value = entry.partition(\"=\")\n",
    "            if not sep:\n",
    "                raise ValueError(\"Unable to parse: %s\" % entry)\n",
    "            default_value = hps._items[key]\n",
    "            if isinstance(default_value, bool):\n",
    "                hps._set(key, value.lower() == \"true\")\n",
    "            elif isinstance(default_value, int):\n",
    "                hps._set(key, int(value))\n",
    "            elif isinstance(default_value, float):\n",
    "                hps._set(key, float(value))\n",
    "            else:\n",
    "                hps._set(key, value)\n",
    "            return hps\n",
    "\n",
    "def get_default_hparams():\n",
    "    return HParams(\n",
    "        z_size=50,\n",
    "        act_func=F.elu,\n",
    "        has_flow=False,\n",
    "        large_encoder=False,\n",
    "        wide_encoder=False,\n",
    "        cuda=True,\n",
    "        decode_dist = log_bernoulli,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f934a0",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aa64637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte.gz' % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ab781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
